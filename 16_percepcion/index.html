<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>SPAN 585</title>
    <meta charset="utf-8" />
    <meta name="author" content="Joseph V. Casillas, PhD" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/hygge.css" rel="stylesheet" />
    <link href="libs/remark-css/rutgers.css" rel="stylesheet" />
    <link href="libs/remark-css/rutgers-fonts.css" rel="stylesheet" />
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <link href="libs/animate.css/animate.xaringan.css" rel="stylesheet" />
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script type="application/json" id="xaringanExtra-editable-docid">{"id":"c385be8e6b22485bb75c414a561f5c00","expires":14}</script>
    <script src="libs/himalaya/himalaya.js"></script>
    <script src="libs/js-cookie/js.cookie.js"></script>
    <link href="libs/editable/editable.css" rel="stylesheet" />
    <script src="libs/editable/editable.js"></script>
    <script src="libs/xaringanExtra-webcam/webcam.js"></script>
    <script id="xaringanExtra-webcam-options" type="application/json">{"width":"200","height":"200","margin":"1em"}</script>
    <script src="https://use.fontawesome.com/5235085b15.js"></script>
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# SPAN 585
]
.subtitle[
## La percepción del habla
]
.author[
### Joseph V. Casillas, PhD
]
.date[
### Rutgers University | Spring 2024</br>Last update: 02/26/24
]

---







# La percepción del habla

### Problemas

- ¿Cómo diferenciamos entre el habla y el ruido?
- ¿Cómo extraemos información relevante de una señal pobre?
- La ausencia de la invarianza

--

### Teorías

- Motor theory
- Direct realist theory
- General auditory and learning approaches

--

### Hallazgos/temas de interés

- Coarticulación
- Percepción categórica
- Interfaz producción/percepción

---

# Problemas

### ¿Cómo diferenciamos entre el habla y el ruido?

### ¿Cómo extraemos información relevante de una señal pobre?

### El input es importante en la adquisición de L1/L2

### ¿Cómo asociamos las unidades lingüísticas con la parte correspondiente de la señal pese a la ausencia de la invarianza?

---
background-image: url(./libs/img/liberman.jpg)
background-position: 105% 50%
background-size: contain

# MT

- Primera teoría importante, surge en los 60 (Haskins)
- Investigador principal: Liberman
--

- 2 hallazgos fundamentales
	- Coarticulación
	- Percepción categórica
	- Idea principal: "linguistic units are coarticulated  
	in production and yet perceived categorically"
--

- 3 aserciones
	- "primitives" son articulatorios ("intended gestures")
	- "Speech is special"
		- la señal codifica la estructura del lenguaje
		- los seres humanos tenemos "algo" (speech  
		module) para descodificar la señal
		- ese "algo" se ocupa de la percepción y la  
		producción
--

- Evidencia
	- percepción "duplex"
	- se procesa el habla en base a cómo se produjo  
	(McGurk effect, comunicación háptica)

---
class: center, middle
background-color: black

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/2k8fHR9jKVM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;

---
class: center, middle
background-color: black

&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/jtsfidRq2tw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen&gt;&lt;/iframe&gt;

---
background-image: url(https://haskinslabs.org/sites/default/files/pictures/picture-143-1462561734.jpg)
background-position: 100% 50%
background-size: contain

# DRT

- Nace de Naïve Realism, basada en MT (Haskins)
- Direct realism (Aristóteles) vs. Indirect realism (Descartes)
--

- Investigadora principal: Fowler
- Similar a MT: "primitives" son articulatorios
- Diferente de MT: 
	- la unidades de percepción son los gestos  
	("intended gesture" vs. "gesture")
	- el habla no es especial (ningún decoder)
--

- algo de parsimonia con otros tipos de percepción  
(e.g., visual)
- Evidencia: véase MT

---
background-image: url(./libs/img/diehl.jpeg)
background-position: 105% 50%
background-size: contain

# GA

- No es una teoría sino "general framework within  
which particular theoretical claims may be  
formulated and tested"
--

- Investigador principal: ?
--

- Surge como alternativa a MT, DRT
- Evidencia en contra de MT, DRT se tiene como  
evidencia a favor de GA
- Rechaza la idea de que "el habla es especial"
--

- Las unidades lingüísticas se asocian a la parte  
corresondiente de la señal mediante el sistema  
auditivo básico y procesos cognitivos (mecanismos  
de aprendizaje)

.pull-left[
.content-box-blue[
"...listeners are able to recover linguistic units via the acoustic signal by utilizing the ‘multiple imperfect acoustic cues’ coupled with sensitivity to the statistical properties present in speech" (Diehl et al., 2004, p. 154).
]
]

---

### Evidencia en contra de MT

- El efecto de la percepción "duplex" puede recrearse usando sonidos que no tienen nada que ver con el habla (e.g. con un portazo)

- Ciertos efectos se recrean en los animales (pájaros, monos, chinchillas)

--

### Evidencia en contra de DRT

- Podemos manipular el tracto vocálico de muchas maneras para generar señales acústicas parecidas 

---
class: inverse, middle, center

# La percepción categórica

---

# La percepción del habla

- ¿Cómo diferenciamos entre el habla y el ruido?

- ¿Cómo extraemos la información relevante de una señal pobre?

---

# La ausencia de invarianza

- Los sonidos del habla nunca se pronuncian de la misma forma

- Si digo **taco** [ˈta.ko] 10 veces, nunca es acústicamente igual 

- ¿Cómo somos capaces de relacionar el sonido con el concepto de un fonema?

---

# La percepción categórica

- "Equal sized physical differences are not equal sized psychologically."

- No percibimos los continuos como continuos...

- Las diferencias dentro de la misma categoría se disminuyen 

- Las diferencias entre categorías se aumentan

---
background-image: url("./libs/img/colors.png")
background-size: contain 

---
background-image: url("./libs/img/pc1.png")
background-size: contain 

---
background-image: url("./libs/img/pc2.png")
background-size: contain 

---

# La percepción categórica

### ¿Cómo estudiamos la percepción categórica?

- 2AFC (identificación)

- AX (discriminación)

---
background-image: url("./libs/img/bapa1.png")
background-size: contain

---
background-image: url("./libs/img/bapa2.png")
background-size: contain

---
background-image: url("./libs/img/bapa3.png")
background-size: contain

---
background-image: url("./libs/img/bapa4.png")
background-size: contain

---
background-image: url("./libs/img/bapa5.png")
background-size: contain

---
background-image: url("./libs/img/bapa6.png")
background-size: contain

---
background-image: url("./libs/img/bapa7.png")
background-size: contain

---
background-image: url("./libs/img/pc3.png")
background-size: contain

---

# La percepción categórica

- "Equal sized physical differences are not equal sized psychologically."

- No percibimos los continuos como continuos...

- Las diferencias dentro de la misma categoría se disminuyen 

- Las diferencias entre categorías se aumentan

.footnote[AX [download](https://www.spanphon.jvcasillas.com/slides/16_percepcion/libs/discriminationAX.zip)]


---
background-color: black



&lt;img src="index_files/figure-html/fig-2afc-1.png" width="100%" /&gt;

---
background-color: black

&lt;img src="index_files/figure-html/fig-fricative-place-1.png" width="100%" /&gt;

---
background-color: black

&lt;img src="index_files/figure-html/fig-stop-place-1.png" width="100%" /&gt;

---
background-color: black

&lt;img src="index_files/figure-html/fig-stop-voicing-1.png" width="100%" /&gt;

---
background-color: black

&lt;img src="index_files/figure-html/fig-vowel-1.png" width="100%" /&gt;

















---
exclude: true
class: inverse, middle, center

# La percepción categórica y el bilingüismo

### **Pallier et al. (1997)**

---
exclude: true

# La percepción categórica

### Pallier et al. (1997)

- Bilingües secuenciales tempranos: español/catalán, catalán/español

- El catalán cuenta con un contraste vocálico que no existe en español (/e/-/ɛ/)

---
exclude: true

# La percepción categórica

### Pallier et al. (1997)

&lt;p&gt;&lt;/p&gt;
&lt;div align="center"&gt;
  &lt;img width="400" src="./libs/img/spanish.png"&gt; 
  &lt;img width="400" src="./libs/img/catalan.png"&gt;
&lt;/div&gt;

---
exclude: true

# La percepción categórica

### Pallier et al. (1997)

- Bilingües secuenciales tempranos: español/catalán, catalán/español

- El catalán cuenta con un contraste vocálico que no existe en español (/e/-/ɛ/)


### Identificación (2AFC)

- "¿Escuchaste [ˈ**pe**.**ɾa**] (Peter) o [ˈ&lt;BLUE&gt;pɛ&lt;/BLUE&gt;.&lt;BLUE&gt;ɾa&lt;/BLUE&gt;] (pera)?"

### Discriminación

- "¿Son iguales o son diferentes?"

---
exclude: true
background-image: url("./libs/img/pallier1.png")
background-size: contain

---
exclude: true
background-image: url("./libs/img/pallier2.png")
background-size: contain

---
exclude: true

# La percepción categórica

### Pallier et al. (1997)

### Conclusión

- Los bilingües tempranos español/catalán no perciben el contraste entre las vocales /e/-/ɛ/ de manera categórica

- Estar expuesto a una edad temprana (durante el periodo sensible) no parece ser suficiente

---
exclude: true
class: inverse, middle, center

# La percepción categórica y el bilingüismo

###**Language-specific stop perception in highly proficient Heritage Speakers**

---
exclude: true

# La percepción categórica 

### Bilingual Language Modes (Grosjean, 1998)

&gt;[...] state of activation of the bilingual's languages and language processing 
&gt;mechanisms at a given point in time (Grosjean, 2002)

- Activation of languages increases/decreases as a function of communicative setting
  - Bilingual mode: both languages activated
  - Unilingual mode: one language activated
- Some bilinguals can reduce cross-language interactions in a unilingual setting (Antoniou et al. 2010; Magloire and Green 1999)
- **Do highly proficient HSs inhibit cross-language interaction effects a unilingual setting?**

---
exclude: true
background-image: url("./libs/img/sp_en_stops.png")
background-size: contain

---
exclude: true

# Method

### Participants

- 9 highly proficient Spanish/English bilinguals
  - 6 females
  - 3 males
- Young adults: ages 20-26 
- Bilingual Language Profile (BLP) questionnaire (-10.16)

---
exclude: true

## Method

### Materials

- Female simultaneous bilingual speaker
  - ba/pa productions
  - 'fri' [fɾi] and [fɹi] productions
  - append lead voicing for /ba/, aspiration for /pa/ (Gonzales &amp; Lotto, 2013)
- Two 13-step continua (-60ms to 60ms, 10ms increments)
  - 'Spanish' ba[fɾi]-pa[fɾi]
  - 'English' ba[fɹi]-pa[fɹi]

---
exclude: true

## Method 

### Procedure

&lt;div style="float:right"&gt;
  &lt;img width="250px" src="./libs/img/2afc1.png"&gt;&lt;/img&gt;  
  &lt;/br&gt;&lt;/br&gt;
  &lt;img width="250px" src="./libs/img/2afc3pa.png"&gt;&lt;/img&gt;
&lt;/div&gt;

- Participants completed two 2AFC identification tasks
    - Session 1: Spanish - ba[fɾi]-pa[fɾi]
        - All instructions, materials in Spanish
        - All correspondence with investigator in Spanish
    - Session 2: English (24 hrs later) - ba[fɹi]-pa[fɹi]
        - All instructions, materials in English
        - All correspondence with investigator in English

---
exclude: true

&lt;div align="center"&gt;
  &lt;img width="100%" src="./libs/img/bafriTuc.png"&gt;
&lt;/div&gt;

&lt;/br&gt;
&gt;- Overall probability of selecting /pa/ decreases by 38% when hearing English stimuli

---
exclude: true

# Summary of findings

- Higher proportion of 'pafri' responses in Spanish session

- HSs shifted their perceptual boundary to accommodate English stimuli in session 2

---
exclude: true

# Discussion

- HSs maintain separate phonetic systems, shift between them according to the language context
- No (less) cross-language activation in unilingual settings

---
exclude: true
class: inverse, center, middle

# Dealing with results

---
exclude: true

# Dealing with results

- Specify the output format
- Import results directly into stats program


```r
library(knitr)
read_chunk('./assets/scripts/analysis.R')
```
---
exclude: true

# Create some data



---
exclude: true


```
## 'data.frame':	700 obs. of  3 variables:
##  $ subjId  : chr  "subj1" "subj1" "subj1" "subj1" ...
##  $ stim    : int  1 2 3 4 5 6 7 1 2 3 ...
##  $ response: num  0 0 0 0 1 1 1 0 0 0 ...
```

.pull-left[


```
##   subjId stim response
## 1  subj1    1        0
## 2  subj1    2        0
## 3  subj1    3        0
## 4  subj1    4        0
## 5  subj1    5        1
## 6  subj1    6        1
```

]

.pull-right[


```
##      subjId stim response
## 695 subj100    2        0
## 696 subj100    3        0
## 697 subj100    4        1
## 698 subj100    5        1
## 699 subj100    6        1
## 700 subj100    7        1
```

]

---
exclude: true

&lt;img src="index_files/figure-html/unnamed-chunk-12-1.png" width="936" /&gt;

---
exclude: true

&lt;img src="index_files/figure-html/unnamed-chunk-13-1.png" width="936" /&gt;

---
exclude: true

&lt;img src="index_files/figure-html/unnamed-chunk-14-1.png" width="936" /&gt;



















---
exclude: true

# Conclusión

&lt;div style="float:right"&gt;
  &lt;img width="100" src="./libs/img/fill.png"&gt;
  &lt;img width="300" src="./libs/img/clap.gif"&gt;
&lt;/div&gt;

- Ahora sabéis lo básico de psychopy2
  - Podéis utilizarlo para crear experimentos psycolingüísticos
  - Tenéis acceso a la plantillas que podéis modificar

&lt;/br&gt;

- La percepción categórica
  - "Equal sized physical differences are not equal sized psychologically."
  - No percibimos los continuos como continuos...



---
exclude: true

## More resources

- http://www.jvcasillas.com/teaching/psychopy/
- http://www.psychopy.org/ 
- http://code.google.com/p/psychopy/ 
- http://www.youtube.com/watch?v=VV6qhuQgsiI

---
exclude: true

## References

- &lt;font size="5"&gt;Gray, J. &amp; Pasmanter, N. (2013). [github][github]&lt;/font&gt;
- &lt;font size="5"&gt;Lejuez, C. W., Aklin, W. M., Zvolensky, M. J., &amp; Pedulla, C. M. (2003). Evaluation of the Balloon Analogue Risk Task (BART) as a predictor of adolescent real-world risk-taking behaviours. Journal of adolescence, 26(4), 475-479. &lt;/font&gt;
- &lt;font size="5"&gt;McGuire, G. (2010, in progress) A Brief Primer on Experimental Designs in Speech Perception Research. http://people.ucsc.edu/~gmcguir1/ &lt;/font&gt;
- &lt;font size="5"&gt;Simonet, M. (2012). El diseño de experimentos para el estudio de la percepción del habla. *Laboratory Approaches to Romance Phonology Conference*. El Colegio de México, México D.F.&lt;/font&gt;


[github]: https://github.com/psychopy/psychopy/tree/master/psychopy/demos/builder/mental_rotation



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/remark/0.14.0/remark.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "monokai",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
